---
phase: 04-guardrails-export
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/api/pyproject.toml
  - apps/api/app/config.py
  - apps/api/app/main.py
  - apps/api/app/dependencies.py
  - apps/api/app/ratelimit/__init__.py
  - apps/api/app/ratelimit/limiter.py
  - apps/api/app/ratelimit/cache.py
  - apps/api/app/ratelimit/router.py
  - apps/api/app/generate/router.py
  - apps/api/app/generate/service.py
  - apps/api/app/generate/schemas.py
  - apps/api/app/scraper/scraper.py
autonomous: true
requirements:
  - RATE-01
  - RATE-03
  - AI-02

must_haves:
  truths:
    - "Anonymous user hitting /api/generate a second time in the same day receives 429 with Retry-After header"
    - "Authenticated user hitting /api/generate more than 3 times in a day receives 429 with Retry-After header"
    - "Two requests for the same URL within 1 hour produce only one outbound HTTP scrape"
    - "User providing X-OpenAI-Key header bypasses rate limit and uses their own API key"
    - "GET /api/usage returns used, limit, and reset fields reflecting current rate limit state"
    - "Generate response includes cache_hit and cache_age_seconds when URL was served from cache"
  artifacts:
    - path: "apps/api/app/ratelimit/limiter.py"
      provides: "Multi-tier rate limiter (anon=1/day, auth=3/day)"
      exports: ["check_rate_limit", "get_usage"]
    - path: "apps/api/app/ratelimit/cache.py"
      provides: "URL scrape cache (Redis SET/GET with 1-hour TTL)"
      exports: ["get_cached_scrape", "cache_scrape"]
    - path: "apps/api/app/ratelimit/router.py"
      provides: "GET /api/usage endpoint"
      exports: ["router"]
    - path: "apps/api/app/config.py"
      provides: "Upstash Redis config vars"
      contains: "upstash_redis_rest_url"
  key_links:
    - from: "apps/api/app/generate/router.py"
      to: "apps/api/app/ratelimit/limiter.py"
      via: "check_rate_limit called before run_generate_pipeline"
      pattern: "check_rate_limit"
    - from: "apps/api/app/generate/service.py"
      to: "apps/api/app/ratelimit/cache.py"
      via: "get_cached_scrape called before scrape_url"
      pattern: "get_cached_scrape"
    - from: "apps/api/app/main.py"
      to: "upstash_redis"
      via: "Redis singleton in lifespan stored in app.state.redis"
      pattern: "app.state.redis"
---

<objective>
Backend rate limiting with Upstash Redis, URL scrape caching, BYOK (bring-your-own-key) support, and usage query endpoint.

Purpose: Protect AI costs by enforcing per-user daily generation limits (anonymous=1/day, auth=3/day per CONTEXT.md locked decision). Reduce duplicate outbound scrapes with 1-hour Redis URL cache. Enable power users to bypass limits via their own OpenAI API key. Expose usage data for frontend counter.

Output: Rate-limited `/api/generate` endpoint, cached scraper pipeline, GET `/api/usage` endpoint, BYOK header support.
</objective>

<execution_context>
@/Users/uzi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/uzi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-guardrails-export/04-RESEARCH.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From apps/api/app/config.py:
```python
class Settings(BaseSettings):
    openai_api_key: str
    neo4j_uri: str = "bolt://localhost:7687"
    neo4j_username: str = "neo4j"
    neo4j_password: str
    clerk_secret_key: str = ""
    clerk_authorized_party: str = ""
    clerk_frontend_api: str = ""
    dev_skip_auth: bool = False
    supabase_url: str = ""
    supabase_key: str = ""
    sentry_dsn: str = ""
    environment: str = "development"
    model_config = {"env_file": ".env"}
```

From apps/api/app/dependencies.py:
```python
def get_neo4j_driver(request: Request) -> Driver:
def get_supabase_client(request: Request) -> Client | None:
# re-export: get_current_user
```

From apps/api/app/main.py lifespan:
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    app.state.neo4j_driver = GraphDatabase.driver(...)
    app.state.supabase = create_client(...) or None
    yield
    app.state.neo4j_driver.close()
```

From apps/api/app/generate/router.py:
```python
@router.post("/generate", response_model=GenerateResponse)
async def generate(request, body, current_user, driver, supabase):
    user_id = current_user.get("sub", "anonymous")
    result = run_generate_pipeline(raw_input=body.input, driver=driver, user_id=user_id, supabase=supabase)
```

From apps/api/app/generate/service.py:
```python
def run_generate_pipeline(raw_input, driver, user_id="anonymous", supabase=None) -> dict:
    # URL path: content = scrape_url(raw_input.strip())
    # Text path: validate_input_length(raw_input); content = raw_input[:32_000]
```

From apps/api/app/generate/schemas.py:
```python
class GenerateMeta(BaseModel):
    session_id: str
    token_count: int
    source_type: Literal["url", "text"]
    processing_ms: int

class GenerateResponse(BaseModel):
    graph: dict[str, list]
    meta: GenerateMeta
```

From apps/api/app/scraper/scraper.py:
```python
def scrape_url(url: str) -> str:
    # SSRF guard -> HTTP request -> extract text -> return text[:MAX_CONTENT_CHARS]
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Upstash Redis singleton + rate limiter module + URL cache module + config</name>
  <files>
    apps/api/pyproject.toml
    apps/api/app/config.py
    apps/api/app/main.py
    apps/api/app/dependencies.py
    apps/api/app/ratelimit/__init__.py
    apps/api/app/ratelimit/limiter.py
    apps/api/app/ratelimit/cache.py
    apps/api/app/ratelimit/router.py
  </files>
  <action>
    **1. Install Upstash Python SDKs:**
    In `apps/api/pyproject.toml` add to dependencies: `"upstash-redis>=1.6.0"`, `"upstash-ratelimit>=1.1.0"`

    Run `cd apps/api && uv sync --no-workspace` to install.

    **2. Add config vars to Settings (apps/api/app/config.py):**
    Add two new fields with empty string defaults (allows dev without Upstash):
    ```python
    # Upstash Redis (Phase 4 — RATE-01, RATE-03, AI-02)
    upstash_redis_rest_url: str = ""
    upstash_redis_rest_token: str = ""
    ```

    **3. Create Redis singleton in lifespan (apps/api/app/main.py):**
    Import `from upstash_redis import Redis`.
    In `lifespan()`, after Supabase init, add:
    ```python
    # Upstash Redis singleton (RATE-01, RATE-03, AI-02)
    if settings.upstash_redis_rest_url and settings.upstash_redis_rest_token:
        app.state.redis = Redis(url=settings.upstash_redis_rest_url, token=settings.upstash_redis_rest_token)
    else:
        app.state.redis = None  # Graceful degradation when not configured
    ```
    No shutdown needed — Upstash Redis is HTTP-based (connectionless).

    **4. Add Redis dependency to dependencies.py:**
    ```python
    def get_redis_client(request: Request):
        """Returns the singleton Upstash Redis client from app.state (RATE-01, RATE-03).
        Returns None if Upstash Redis is not configured."""
        return getattr(request.app.state, "redis", None)
    ```

    **5. Create rate limiter module (apps/api/app/ratelimit/):**

    Create `apps/api/app/ratelimit/__init__.py` (empty).

    Create `apps/api/app/ratelimit/limiter.py`:
    ```python
    import time
    from fastapi import HTTPException
    from upstash_ratelimit import Ratelimit, FixedWindow

    def _build_limiters(redis):
        """Build anon and auth rate limiters from a Redis instance."""
        anon = Ratelimit(redis=redis, limiter=FixedWindow(max_requests=1, window=86400), prefix="ratelimit:anon")
        auth = Ratelimit(redis=redis, limiter=FixedWindow(max_requests=3, window=86400), prefix="ratelimit:auth")
        return anon, auth

    def check_rate_limit(redis, user_id: str, ip: str) -> None:
        """Check per-user daily rate limit. Raises HTTPException(429) if exceeded.
        Skips check if Redis is not configured (dev without Upstash)."""
        if redis is None:
            return
        is_anonymous = (user_id == "anonymous")
        anon_limiter, auth_limiter = _build_limiters(redis)
        limiter = anon_limiter if is_anonymous else auth_limiter
        identifier = ip if is_anonymous else user_id
        result = limiter.limit(identifier)
        if not result.allowed:
            seconds_until_reset = max(1, int(result.reset - time.time()))
            raise HTTPException(
                status_code=429,
                detail={"error": "rate_limited", "retry_after": seconds_until_reset, "message": "Daily limit reached"},
                headers={"Retry-After": str(seconds_until_reset)},
            )

    def get_usage(redis, user_id: str, ip: str) -> dict:
        """Return usage info without consuming a request.
        Uses the ratelimit SDK's `remaining` call to peek at state."""
        if redis is None:
            return {"used": 0, "limit": 0, "reset": 0}
        is_anonymous = (user_id == "anonymous")
        anon_limiter, auth_limiter = _build_limiters(redis)
        limiter = anon_limiter if is_anonymous else auth_limiter
        identifier = ip if is_anonymous else user_id
        result = limiter.remaining(identifier)
        max_requests = 1 if is_anonymous else 3
        used = max_requests - result.remaining
        return {"used": used, "limit": max_requests, "reset": int(result.reset)}
    ```

    IMPORTANT: `_build_limiters` is called per-request because the Ratelimit object is lightweight (just config + redis reference). Per Upstash SDK docs, no connection pooling is involved.

    Note: The `remaining()` method on the Ratelimit SDK returns `RemainingResponse` with `remaining` (int) and `reset` (float, Unix timestamp). If `remaining()` is not available in the Python SDK, fall back to using `limit()` but note it consumes one request. In that case, use a separate "peek" Redis key pattern: read the current window key directly via `redis.get(f"ratelimit:{prefix}:{identifier}:{window_key}")`. The executor should verify the SDK API and adjust accordingly.

    **6. Create URL cache module (apps/api/app/ratelimit/cache.py):**
    ```python
    import hashlib

    def _cache_key(url: str) -> str:
        normalized = url.strip().lower().rstrip("/")
        url_hash = hashlib.sha256(normalized.encode()).hexdigest()
        return f"scrape:{url_hash}"

    def get_cached_scrape(redis, url: str) -> tuple[str | None, int | None]:
        """Returns (cached_text, seconds_ago) or (None, None)."""
        if redis is None:
            return None, None
        key = _cache_key(url)
        text = redis.get(key)
        if text is None:
            return None, None
        ttl = redis.ttl(key)
        seconds_ago = 3600 - ttl if ttl and ttl > 0 else None
        return text, seconds_ago

    def cache_scrape(redis, url: str, text: str) -> None:
        """Store scraped text with 1-hour TTL."""
        if redis is None:
            return
        key = _cache_key(url)
        redis.set(key, text, ex=3600)
    ```

    **7. Create usage endpoint (apps/api/app/ratelimit/router.py):**
    ```python
    from fastapi import APIRouter, Depends, Request
    from app.dependencies import get_current_user, get_redis_client
    from app.ratelimit.limiter import get_usage

    router = APIRouter(prefix="/api", tags=["ratelimit"])

    @router.get("/usage")
    async def usage(
        request: Request,
        current_user: dict = Depends(get_current_user),
        redis=Depends(get_redis_client),
    ):
        user_id = current_user.get("sub", "anonymous")
        ip = request.client.host if request.client else "127.0.0.1"
        return get_usage(redis, user_id, ip)
    ```

    **8. Register the usage router in main.py:**
    Import `from app.ratelimit.router import router as ratelimit_router` and add `app.include_router(ratelimit_router)` after the generate_router.
  </action>
  <verify>
    <automated>cd apps/api && uv run python -c "from app.ratelimit.limiter import check_rate_limit, get_usage; from app.ratelimit.cache import get_cached_scrape, cache_scrape; from app.ratelimit.router import router; print('All imports OK')"</automated>
  </verify>
  <done>
    - Settings has upstash_redis_rest_url and upstash_redis_rest_token
    - app.state.redis created in lifespan (or None if not configured)
    - get_redis_client dependency returns Redis | None
    - limiter.py exports check_rate_limit and get_usage
    - cache.py exports get_cached_scrape and cache_scrape
    - GET /api/usage endpoint registered and returning usage data
    - upstash-redis and upstash-ratelimit in pyproject.toml
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire rate limit + URL cache + BYOK into generate pipeline</name>
  <files>
    apps/api/app/generate/router.py
    apps/api/app/generate/service.py
    apps/api/app/generate/schemas.py
  </files>
  <action>
    **1. Update GenerateMeta schema (apps/api/app/generate/schemas.py):**
    Add two optional fields to `GenerateMeta`:
    ```python
    cache_hit: bool = False
    cache_age_seconds: int | None = None
    ```
    These support the frontend "Cached -- scraped 23 min ago" indicator (CONTEXT.md locked decision).

    **2. Update shared-types (packages/shared-types/src/index.ts):**
    Add to `GenerateMeta` interface:
    ```typescript
    cache_hit: boolean
    cache_age_seconds: number | null
    ```

    **3. Update run_generate_pipeline (apps/api/app/generate/service.py):**

    Add new parameters: `redis=None`, `openai_api_key: str | None = None`, `force_refresh: bool = False`.

    Add import: `from app.ratelimit.cache import get_cached_scrape, cache_scrape`

    In the URL path (where `source_type = "url"`):
    - Before calling `scrape_url()`, check cache: `cached_text, cache_age = get_cached_scrape(redis, raw_input.strip())`
    - If `cached_text is not None` and not `force_refresh`: use `cached_text` as `content`, set `cache_hit = True`, `cache_age_seconds = cache_age`
    - If no cache hit or force_refresh: call `scrape_url()` as before, then `cache_scrape(redis, raw_input.strip(), content)` to store result
    - Add `cache_hit` and `cache_age_seconds` to the returned meta dict

    For BYOK support:
    - If `openai_api_key` is provided, create a temporary OpenAI client: `client = OpenAI(api_key=openai_api_key)` instead of using `_get_openai_client()`.
    - Otherwise use the existing `_get_openai_client()` singleton with the server key.
    - CRITICAL: Never log or persist the user's API key. Do NOT include it in Sentry context or request_log.

    **4. Update generate router (apps/api/app/generate/router.py):**

    Add imports: `from app.dependencies import get_redis_client`, `from app.ratelimit.limiter import check_rate_limit`

    Add `redis=Depends(get_redis_client)` to the generate endpoint signature.

    Add `GenerateRequest` field: `force_refresh: bool = False` (optional, defaults to False).

    Before calling `run_generate_pipeline()`:
    ```python
    # BYOK: if user provides their own OpenAI API key, bypass rate limit
    openai_key = request.headers.get("x-openai-key")
    if not openai_key:
        # Check per-user daily rate limit (RATE-01)
        ip = request.client.host if request.client else "127.0.0.1"
        check_rate_limit(redis, user_id, ip)
    ```

    Pass new params to `run_generate_pipeline()`:
    ```python
    result = run_generate_pipeline(
        raw_input=body.input,
        driver=driver,
        user_id=user_id,
        supabase=supabase,
        redis=redis,
        openai_api_key=openai_key,
        force_refresh=body.force_refresh,
    )
    ```

    CRITICAL: Do NOT log `openai_key` in the request_log insert. The existing code does not log headers, so this is already safe. But verify it.

    Also add `force_refresh` to the `GenerateRequest` schema:
    ```python
    force_refresh: bool = False  # CONTEXT.md: bypass URL cache, counts as generation
    ```
  </action>
  <verify>
    <automated>cd apps/api && uv run python -c "from app.generate.schemas import GenerateMeta; m = GenerateMeta(session_id='x', token_count=0, source_type='url', processing_ms=0, cache_hit=True, cache_age_seconds=120); print('cache_hit:', m.cache_hit, 'cache_age:', m.cache_age_seconds)" && uv run python -c "from app.generate.router import router; print('Router imports OK')"</automated>
  </verify>
  <done>
    - GenerateMeta has cache_hit and cache_age_seconds fields
    - GenerateRequest has force_refresh field
    - shared-types GenerateMeta has cache_hit and cache_age_seconds
    - generate endpoint checks rate limit before pipeline (unless BYOK)
    - URL cache: check before scrape, store after scrape
    - BYOK: X-OpenAI-Key header creates temporary client, bypasses rate limit
    - Force refresh: bypasses cache but still counts against rate limit
    - No user API key logged anywhere
  </done>
</task>

</tasks>

<verification>
1. `cd apps/api && uv run python -c "from app.ratelimit.limiter import check_rate_limit, get_usage; from app.ratelimit.cache import get_cached_scrape, cache_scrape; print('OK')"` — all imports resolve
2. `cd apps/api && uv run python -c "from app.generate.schemas import GenerateMeta; print(GenerateMeta.model_fields.keys())"` — includes cache_hit, cache_age_seconds
3. `cd apps/api && uv run pytest tests/ -x` — existing tests still pass (rate limit and cache are None-safe)
4. Grep: no string containing `x-openai-key` or `openai_key` in any logging/Sentry/request_log code
</verification>

<success_criteria>
- Upstash Redis SDK installed and configured with graceful degradation
- Rate limiter enforces anon=1/day, auth=3/day via FixedWindow(86400)
- URL cache: SHA-256 keyed, 1-hour TTL, cache-before-scrape pattern
- BYOK: X-OpenAI-Key header bypasses rate limit, uses user's key transiently
- GET /api/usage returns {used, limit, reset}
- GenerateMeta includes cache_hit and cache_age_seconds
- All existing tests pass (None-safe for Redis)
</success_criteria>

<output>
After completion, create `.planning/phases/04-guardrails-export/04-01-SUMMARY.md`
</output>
