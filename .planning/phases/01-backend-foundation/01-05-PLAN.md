---
phase: 01-backend-foundation
plan: 05
type: execute
wave: 3
depends_on:
  - "01-02"
  - "01-03"
  - "01-04"
files_modified:
  - apps/api/app/generate/schemas.py
  - apps/api/app/generate/prompts.py
  - apps/api/app/generate/service.py
  - apps/api/app/generate/router.py
  - apps/api/app/main.py
  - apps/api/tests/test_generate.py
autonomous: true
requirements:
  - AI-01
  - AI-03
  - AI-04

user_setup:
  - service: openai
    why: "GPT-4o structured entity extraction — the core AI pipeline"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Platform -> API Keys -> Create new secret key"

must_haves:
  truths:
    - "POST /api/generate with a valid JWT and text input returns 200 with graph.nodes and graph.edges"
    - "Returned nodes include all 5 entity types: Investor, Project, Round, Narrative, Person"
    - "POST /api/generate with text shorter than 200 chars returns 400 with the exact AI-04 message"
    - "POST /api/generate with a URL input scrapes the URL and passes content to GPT-4o (source_type=url)"
    - "POST /api/generate with raw text skips scraping and goes straight to GPT-4o (source_type=text)"
    - "Response meta includes all 4 fields: session_id, token_count, source_type, processing_ms"
    - "No request without a valid Clerk JWT can reach the generation logic (401 returned first)"
  artifacts:
    - path: "apps/api/app/generate/schemas.py"
      provides: "Pydantic models: VCKnowledgeGraph, GraphNode, GraphEdge, GenerateRequest, GenerateResponse"
      contains: "VCKnowledgeGraph"
    - path: "apps/api/app/generate/prompts.py"
      provides: "GPT-4o system prompt constant for VC entity extraction"
      contains: "SYSTEM_PROMPT"
    - path: "apps/api/app/generate/service.py"
      provides: "extract_graph() calling OpenAI native structured outputs"
      contains: "client.beta.chat.completions.parse"
    - path: "apps/api/app/generate/router.py"
      provides: "POST /api/generate endpoint"
      contains: "router.post"
    - path: "apps/api/tests/test_generate.py"
      provides: "Integration tests for the generate endpoint"
      contains: "test_generate_text_input_returns_graph"
  key_links:
    - from: "apps/api/app/generate/router.py"
      to: "apps/api/app/dependencies.py"
      via: "Depends(get_current_user) + Depends(get_neo4j_driver)"
      pattern: "Depends\\(get_current_user\\)"
    - from: "apps/api/app/generate/service.py"
      to: "openai client"
      via: "client.beta.chat.completions.parse() with VCKnowledgeGraph response_format"
      pattern: "client\\.beta\\.chat\\.completions\\.parse"
    - from: "apps/api/app/generate/service.py"
      to: "apps/api/app/graph/repository.py"
      via: "persist_graph() called after extract_graph()"
      pattern: "persist_graph"
    - from: "apps/api/app/generate/router.py"
      to: "apps/api/app/scraper/scraper.py"
      via: "scrape_url() called when input starts with https://"
      pattern: "scrape_url"
---

<objective>
Build the `POST /api/generate` endpoint — the core product feature. Wires together the SSRF scraper (Plan 02/03), Neo4j repository (Plan 03), and Clerk auth (Plan 04) into a complete pipeline: receive input → optionally scrape → extract VC entities via GPT-4o → persist graph → return structured JSON.

Purpose: This is the endpoint the Phase 1 success criteria tests. Without it, none of the security work is exposed or verifiable end-to-end.

Output: Complete `apps/api/app/generate/` domain with schemas, system prompt, service, and router. The endpoint is protected by Clerk JWT, validates input length, detects source type, and returns the CONTEXT.md API contract shape.
</objective>

<execution_context>
@/Users/uzi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/uzi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-backend-foundation/01-CONTEXT.md
@.planning/phases/01-backend-foundation/01-RESEARCH.md
@.planning/phases/01-backend-foundation/01-01-SUMMARY.md
@.planning/phases/01-backend-foundation/01-02-SUMMARY.md
@.planning/phases/01-backend-foundation/01-03-SUMMARY.md
@.planning/phases/01-backend-foundation/01-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pydantic schemas, GPT-4o system prompt, and extraction service</name>
  <files>
    apps/api/app/generate/schemas.py
    apps/api/app/generate/prompts.py
    apps/api/app/generate/service.py
  </files>
  <action>
Create the three non-routing files for the generate domain. These can be written independently of the router.

**`apps/api/app/generate/schemas.py`:**

This is the source of truth for:
1. The GPT-4o response schema (VCKnowledgeGraph — what OpenAI structured outputs will enforce)
2. The API request/response contract (from CONTEXT.md locked decisions)

```python
from typing import Any, Literal
from pydantic import BaseModel, Field

# Entity and relationship types from REQUIREMENTS.md AI-01
EntityType = Literal["Investor", "Project", "Round", "Narrative", "Person"]

RelationshipType = Literal[
    "LED",
    "INVESTED_IN",
    "CO_INVESTED",
    "RAISED",
    "FOUNDED",
    "PARTNERS_AT",
    "FOCUSES_ON",
    "CLASSIFIED_AS",
]


class GraphNode(BaseModel):
    id: str = Field(
        description="Unique slug identifier derived from entity name, e.g., 'paradigm-capital'"
    )
    label: str = Field(description="Display name, e.g., 'Paradigm Capital'")
    type: EntityType
    properties: dict[str, Any] = Field(
        default_factory=dict,
        description=(
            "Entity-specific properties. "
            "Investor: aum, stage_focus, chain_focus. "
            "Project: token_ticker, chain, category. "
            "Round: amount_usd, stage, date. "
            "Person: title, firm. "
            "Narrative: description."
        ),
    )


class GraphEdge(BaseModel):
    source: str = Field(description="Source node id (must match a node id in the graph)")
    target: str = Field(description="Target node id (must match a node id in the graph)")
    relationship: RelationshipType


class VCKnowledgeGraph(BaseModel):
    """
    VC ecosystem knowledge graph with typed entities and relationships.
    Used as response_format for client.beta.chat.completions.parse() (AI-01).
    OpenAI native structured outputs guarantee this schema is always returned.
    """
    nodes: list[GraphNode]
    edges: list[GraphEdge]


# API request/response models (CONTEXT.md API Response Contract)

class GenerateRequest(BaseModel):
    input: str = Field(
        description=(
            "Text or HTTPS URL to analyze. "
            "Minimum 200 characters (AI-04). "
            "URL inputs are scraped; text inputs go directly to GPT-4o (AI-03)."
        )
    )
    # Note: min_length validation is done in the service/route via validate_input_length()
    # (from ssrf.py Plan 02) to produce our custom error shape, not Pydantic's 422.


class GenerateMeta(BaseModel):
    session_id: str
    token_count: int
    source_type: Literal["url", "text"]
    processing_ms: int


class GenerateResponse(BaseModel):
    graph: dict[str, list]   # {"nodes": [...], "edges": [...]}
    meta: GenerateMeta
```

**`apps/api/app/generate/prompts.py`:**

The system prompt instructs GPT-4o on the 5 entity types, 8 relationship types, and deduplication rules (per CONTEXT.md Entity Deduplication decision: GPT-4o handles within-request deduplication via system prompt).

```python
SYSTEM_PROMPT = """You are a crypto venture capital analyst. Extract a structured knowledge graph from the provided text.

## Entity Types

Extract these five entity types only. Do not create other types.

- **Investor**: Venture capital firms, crypto funds, angels. Properties: aum (string, e.g., "$4.5B"), stage_focus (seed/series-a/growth/multi-stage), chain_focus (ethereum/solana/multi-chain/chain-agnostic)
- **Project**: Crypto protocols, startups, DAOs. Properties: token_ticker (if launched), chain (primary chain), category (defi/l1/l2/infrastructure/gaming/nft/other)
- **Round**: Funding events. Properties: amount_usd (string, e.g., "$50M"), stage (pre-seed/seed/series-a/series-b/series-c/strategic), date (YYYY-MM if mentioned)
- **Narrative**: Investment themes or market categories. Properties: description (1 sentence)
- **Person**: Named individuals. Properties: title (e.g., "General Partner"), firm (their employer)

## Relationship Types

Use only these relationship types:
- LED: Investor LED a Round
- INVESTED_IN: Investor INVESTED_IN a Project or Round
- CO_INVESTED: Investor CO_INVESTED with another Investor (in same round)
- RAISED: Project RAISED a Round
- FOUNDED: Person FOUNDED a Project
- PARTNERS_AT: Person PARTNERS_AT an Investor
- FOCUSES_ON: Investor FOCUSES_ON a Narrative
- CLASSIFIED_AS: Project CLASSIFIED_AS a Narrative

## Rules

1. Each entity appears exactly once — deduplicate by name within this response
2. Use lowercase-hyphenated slugs for node IDs (e.g., "paradigm-capital", "uniswap-v4", "series-b-2024")
3. Only extract entities explicitly mentioned — do not infer or hallucinate
4. If no VC entities are found, return empty nodes and edges arrays
5. Properties are optional — omit unknown values rather than guessing
"""
```

**`apps/api/app/generate/service.py`:**

Orchestrates the pipeline: source type detection → optional scrape → GPT-4o extraction → Neo4j persistence.

```python
import time
import uuid
from openai import OpenAI

from app.config import settings
from app.generate.schemas import VCKnowledgeGraph
from app.generate.prompts import SYSTEM_PROMPT
from app.scraper.scraper import scrape_url
from app.scraper.ssrf import validate_input_length
from app.graph.repository import persist_graph

# OpenAI client — module-level singleton (one instance per worker process)
_openai_client: OpenAI | None = None


def _get_openai_client() -> OpenAI:
    global _openai_client
    if _openai_client is None:
        _openai_client = OpenAI(api_key=settings.openai_api_key)
    return _openai_client


def run_generate_pipeline(
    raw_input: str,
    driver,
) -> dict:
    """
    Full generate pipeline (AI-01, AI-02, AI-03, AI-04):
    1. Validate input length (≥200 chars) via validate_input_length()
    2. Detect source type: URL (starts with https://) or raw text
    3. If URL: scrape via scrape_url() (includes SSRF guard from Plan 02/03)
    4. Call GPT-4o via native structured outputs → VCKnowledgeGraph
    5. Persist to Neo4j via persist_graph() with session_id
    6. Return API response matching CONTEXT.md contract

    Returns dict matching GenerateResponse schema:
    {
        "graph": {"nodes": [...], "edges": [...]},
        "meta": {"session_id": ..., "token_count": ..., "source_type": ..., "processing_ms": ...}
    }
    """
    start_ms = int(time.time() * 1000)

    # AI-04: Reject inputs shorter than 200 characters
    # validate_input_length raises HTTPException(400) with exact required message
    validate_input_length(raw_input)

    # AI-03: Source type detection
    # URL inputs: starts with "https://" (HTTP is blocked by SSRF validator anyway)
    # Text inputs: everything else
    session_id = str(uuid.uuid4())

    if raw_input.strip().startswith("https://"):
        source_type = "url"
        content = scrape_url(raw_input.strip())
    else:
        source_type = "text"
        content = raw_input[:32_000]  # cap at 32k even for direct text (AI-02)

    # AI-01: GPT-4o structured extraction via native structured outputs
    # client.beta.chat.completions.parse() guarantees VCKnowledgeGraph schema
    # No manual JSON repair needed — native structured outputs handles it
    client = _get_openai_client()
    try:
        response = client.beta.chat.completions.parse(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": content},
            ],
            response_format=VCKnowledgeGraph,
        )
    except Exception as e:
        from fastapi import HTTPException
        raise HTTPException(status_code=503, detail={
            "error": "service_unavailable",
            "message": "OpenAI service unavailable — please try again",
        })

    parsed: VCKnowledgeGraph = response.choices[0].message.parsed
    token_count: int = response.usage.total_tokens

    # Serialize to dicts for Neo4j persistence and response
    nodes = [node.model_dump() for node in parsed.nodes]
    edges = [edge.model_dump() for edge in parsed.edges]

    # Persist to Neo4j — parameterized Cypher only (SEC-02, from Plan 03)
    try:
        persist_graph(driver, session_id=session_id, nodes=nodes, edges=edges)
    except Exception as e:
        from fastapi import HTTPException
        raise HTTPException(status_code=503, detail={
            "error": "service_unavailable",
            "message": "Graph database unavailable — please try again",
        })

    processing_ms = int(time.time() * 1000) - start_ms

    return {
        "graph": {"nodes": nodes, "edges": edges},
        "meta": {
            "session_id": session_id,
            "token_count": token_count,
            "source_type": source_type,
            "processing_ms": processing_ms,
        },
    }
```
  </action>
  <verify>
    <automated>cd "/Users/uzi/Documents/Git Projects/instagraph-vc/apps/api" && uv run python -c "from app.generate.schemas import VCKnowledgeGraph, GenerateRequest, GenerateResponse; from app.generate.prompts import SYSTEM_PROMPT; from app.generate.service import run_generate_pipeline; print('Generate domain imports OK')"</automated>
    <manual>Confirm `service.py` uses `client.beta.chat.completions.parse()` (not `client.chat.completions.create()`). Confirm both OpenAI and Neo4j failures raise HTTPException(503) with `error: "service_unavailable"`. Confirm `validate_input_length()` is called before scraping or GPT-4o call.</manual>
  </verify>
  <done>
    - All three files import without error
    - `VCKnowledgeGraph` has `nodes: list[GraphNode]` and `edges: list[GraphEdge]`
    - `SYSTEM_PROMPT` covers all 5 entity types and 8 relationship types from AI-01
    - `run_generate_pipeline()` detects source type, scrapes URLs, calls GPT-4o with structured outputs, persists graph, returns correct response shape
    - OpenAI and Neo4j failures produce 503 responses
  </done>
</task>

<task type="auto">
  <name>Task 2: POST /api/generate router, app registration, and integration tests</name>
  <files>
    apps/api/app/generate/router.py
    apps/api/app/main.py
    apps/api/tests/test_generate.py
  </files>
  <action>
Create the FastAPI router that exposes `POST /api/generate`, register it in `main.py`, and write integration tests that mock the OpenAI and Neo4j calls.

**`apps/api/app/generate/router.py`:**

```python
from fastapi import APIRouter, Depends
from neo4j import Driver

from app.dependencies import get_current_user, get_neo4j_driver
from app.generate.schemas import GenerateRequest, GenerateResponse
from app.generate.service import run_generate_pipeline

router = APIRouter(prefix="/api", tags=["generate"])


@router.post("/generate", response_model=GenerateResponse)
async def generate(
    body: GenerateRequest,
    current_user: dict = Depends(get_current_user),
    driver: Driver = Depends(get_neo4j_driver),
) -> GenerateResponse:
    """
    Generate a VC knowledge graph from text or URL input (AI-01, AI-02, AI-03).

    Authentication: Requires valid Clerk JWT Bearer token (SEC-03).
    Rejected immediately with 401 if token is missing or invalid.

    Request body: {"input": "text or https://url"}

    Returns:
    {
        "graph": {
            "nodes": [{"id": "...", "label": "...", "type": "...", "properties": {...}}],
            "edges": [{"source": "...", "target": "...", "relationship": "..."}]
        },
        "meta": {
            "session_id": "uuid",
            "token_count": 1234,
            "source_type": "url" | "text",
            "processing_ms": 4500
        }
    }
    """
    result = run_generate_pipeline(raw_input=body.input, driver=driver)
    return result
```

**Update `apps/api/app/main.py` to register the router:**

Read the existing `main.py` (from Plan 01) and add the router import and include:

```python
# Add to main.py (after the existing FastAPI app definition):
from app.generate.router import router as generate_router
app.include_router(generate_router)
```

The full updated `main.py` should look like:
```python
from contextlib import asynccontextmanager
from fastapi import FastAPI
from neo4j import GraphDatabase
from app.config import settings
from app.generate.router import router as generate_router

@asynccontextmanager
async def lifespan(app: FastAPI):
    app.state.neo4j_driver = GraphDatabase.driver(
        settings.neo4j_uri,
        auth=(settings.neo4j_username, settings.neo4j_password),
    )
    app.state.neo4j_driver.verify_connectivity()
    with app.state.neo4j_driver.session() as session:
        session.run(
            "CREATE INDEX entity_session_id IF NOT EXISTS "
            "FOR (n:Entity) ON (n.session_id)"
        )
    yield
    app.state.neo4j_driver.close()

app = FastAPI(
    title="GraphVC API",
    version="0.1.0",
    lifespan=lifespan,
)

app.include_router(generate_router)

@app.get("/health")
async def health():
    return {"status": "ok"}
```

**`apps/api/tests/test_generate.py`:**

Integration tests using FastAPI TestClient (`httpx.AsyncClient`) with mocked OpenAI and Neo4j:

```python
import pytest
from unittest.mock import patch, MagicMock, AsyncMock
from fastapi.testclient import TestClient


@pytest.fixture
def mock_neo4j_driver():
    """Provides a mock Neo4j driver for tests."""
    driver = MagicMock()
    session_mock = MagicMock()
    driver.session.return_value.__enter__ = MagicMock(return_value=session_mock)
    driver.session.return_value.__exit__ = MagicMock(return_value=False)
    session_mock.run.return_value = MagicMock()
    return driver


@pytest.fixture
def app_with_mocks(mock_neo4j_driver):
    """Creates FastAPI test app with mocked Neo4j driver in app.state."""
    from app.main import app
    from app.dependencies import get_neo4j_driver

    app.state.neo4j_driver = mock_neo4j_driver

    # Override the neo4j driver dependency
    app.dependency_overrides[get_neo4j_driver] = lambda: mock_neo4j_driver
    yield app
    app.dependency_overrides.clear()


@pytest.fixture
def valid_jwt_user():
    """Mocked JWT payload representing a valid authenticated user."""
    return {"sub": "user_test123", "azp": "http://localhost:3000"}


SAMPLE_GRAPH_RESPONSE = {
    "nodes": [
        {"id": "paradigm-capital", "label": "Paradigm Capital", "type": "Investor", "properties": {"aum": "$4.5B"}},
        {"id": "uniswap", "label": "Uniswap", "type": "Project", "properties": {"token_ticker": "UNI"}},
        {"id": "series-a-2024", "label": "Series A 2024", "type": "Round", "properties": {"amount_usd": "$50M"}},
    ],
    "edges": [
        {"source": "paradigm-capital", "target": "series-a-2024", "relationship": "LED"},
        {"source": "uniswap", "target": "series-a-2024", "relationship": "RAISED"},
    ],
}


def make_mock_openai_response(graph_data):
    """Creates a mock OpenAI parse response with the given graph data."""
    from app.generate.schemas import VCKnowledgeGraph, GraphNode, GraphEdge

    parsed = VCKnowledgeGraph(
        nodes=[GraphNode(**n) for n in graph_data["nodes"]],
        edges=[GraphEdge(**e) for e in graph_data["edges"]],
    )

    mock_response = MagicMock()
    mock_response.choices = [MagicMock()]
    mock_response.choices[0].message.parsed = parsed
    mock_response.usage.total_tokens = 512
    return mock_response


class TestGenerateEndpoint:
    @patch("app.generate.service._get_openai_client")
    @patch("app.auth.clerk.get_current_user")
    def test_generate_text_input_returns_graph(
        self, mock_auth, mock_openai_factory, app_with_mocks, valid_jwt_user
    ):
        mock_auth.return_value = valid_jwt_user
        mock_client = MagicMock()
        mock_client.beta.chat.completions.parse.return_value = make_mock_openai_response(SAMPLE_GRAPH_RESPONSE)
        mock_openai_factory.return_value = mock_client

        # Override auth dependency
        from app.dependencies import get_current_user
        app_with_mocks.dependency_overrides[get_current_user] = lambda: valid_jwt_user

        with TestClient(app_with_mocks) as client:
            response = client.post(
                "/api/generate",
                json={"input": "Paradigm Capital led a $50M Series A in Uniswap. " * 10},
            )

        assert response.status_code == 200
        data = response.json()
        assert "graph" in data
        assert "nodes" in data["graph"]
        assert "edges" in data["graph"]
        assert "meta" in data
        assert data["meta"]["source_type"] == "text"
        assert "session_id" in data["meta"]
        assert "token_count" in data["meta"]
        assert "processing_ms" in data["meta"]

    def test_generate_rejects_missing_auth(self, app_with_mocks):
        with TestClient(app_with_mocks) as client:
            response = client.post(
                "/api/generate",
                json={"input": "Some funding announcement text. " * 10},
            )
        assert response.status_code == 401
        assert response.json()["detail"]["error"] == "unauthorized"

    @patch("app.auth.clerk.get_current_user")
    def test_generate_rejects_short_input(self, mock_auth, app_with_mocks, valid_jwt_user):
        from app.dependencies import get_current_user
        app_with_mocks.dependency_overrides[get_current_user] = lambda: valid_jwt_user

        with TestClient(app_with_mocks) as client:
            response = client.post(
                "/api/generate",
                json={"input": "too short"},
                headers={"Authorization": "Bearer fake.jwt.token"},
            )

        assert response.status_code == 400
        detail = response.json()["detail"]
        assert detail["error"] == "input_too_short"
        assert "Input too short" in detail["message"]
        assert "paste a full funding announcement" in detail["message"]

    @patch("app.generate.service._get_openai_client")
    @patch("app.scraper.scraper.validate_url")
    @patch("app.scraper.scraper.requests.get")
    def test_generate_url_input_scrapes_and_extracts(
        self, mock_requests_get, mock_validate, mock_openai_factory, app_with_mocks, valid_jwt_user
    ):
        from app.dependencies import get_current_user
        app_with_mocks.dependency_overrides[get_current_user] = lambda: valid_jwt_user

        # Mock the scraper
        mock_response = MagicMock()
        mock_response.is_redirect = False
        mock_response.text = "<html><body>" + "<p>Paradigm Capital invested $50M in Uniswap. </p>" * 30 + "</body></html>"
        mock_response.raise_for_status.return_value = None
        mock_requests_get.return_value = mock_response

        # Mock OpenAI
        mock_client = MagicMock()
        mock_client.beta.chat.completions.parse.return_value = make_mock_openai_response(SAMPLE_GRAPH_RESPONSE)
        mock_openai_factory.return_value = mock_client

        with TestClient(app_with_mocks) as client:
            response = client.post(
                "/api/generate",
                json={"input": "https://techcrunch.com/article"},
            )

        assert response.status_code == 200
        data = response.json()
        assert data["meta"]["source_type"] == "url"
```
  </action>
  <verify>
    <automated>cd "/Users/uzi/Documents/Git Projects/instagraph-vc/apps/api" && uv run pytest tests/test_generate.py -v --tb=short 2>&1 | tail -20</automated>
    <manual>
      1. Confirm `router.py` uses `Depends(get_current_user)` on the POST /api/generate route
      2. Confirm `main.py` includes `app.include_router(generate_router)`
      3. Run `uv run uvicorn app.main:app --reload` locally (with .env populated) and hit `GET /health` — returns `{"status": "ok"}`
      4. With a real Clerk JWT: `curl -X POST http://localhost:8000/api/generate -H "Authorization: Bearer $JWT" -H "Content-Type: application/json" -d '{"input": "short"}' ` — returns 400 with exact AI-04 message
    </manual>
  </verify>
  <done>
    - `pytest tests/test_generate.py` passes with 0 failures
    - `POST /api/generate` without Authorization header returns 401
    - `POST /api/generate` with input < 200 chars returns 400 with exact AI-04 message
    - `POST /api/generate` with text input sets `meta.source_type = "text"` (bypasses scraper)
    - `POST /api/generate` with URL input sets `meta.source_type = "url"` (goes through scraper)
    - Response includes all 4 meta fields: session_id, token_count, source_type, processing_ms
    - Router registered in `main.py` via `app.include_router(generate_router)`
  </done>
</task>

</tasks>

<verification>
Full phase verification after Plan 05 completes:

1. `cd apps/api && uv run pytest tests/ -v` — all tests pass across test_ssrf.py, test_scraper.py, test_generate.py
2. `grep -rn "\.format(" apps/api/app/` — returns empty (SEC-02: no string formatting in Cypher)
3. `grep -rn 'f"' apps/api/app/graph/` — returns empty (parameterized Cypher clean)
4. `grep "allow_redirects=False" apps/api/app/scraper/scraper.py` — returns match (SSRF redirect bypass blocked)
5. `grep "Depends(get_current_user)" apps/api/app/generate/router.py` — returns match (auth guard in place)
6. `docker compose config --quiet` — exits 0 (valid compose file)

Security sweep (Phase 1 success criteria verification):
- SC #2: `curl -X POST http://localhost:8000/api/generate -H "Authorization: Bearer $JWT" -d '{"input": "https://127.0.0.1/secret"}' --header "Content-Type: application/json"` → 400
- SC #3: `grep -rn "\.format(" apps/api/app/` → 0 results
- SC #4: `curl -X POST http://localhost:8000/api/generate -d '{"input": "..."}' --header "Content-Type: application/json"` (no auth) → 401
- SC #5: Input = "short" → 400 with exact message
</verification>

<success_criteria>
- `POST /api/generate` with valid JWT + text ≥ 200 chars → 200 with `{graph: {nodes, edges}, meta: {session_id, token_count, source_type, processing_ms}}`
- `POST /api/generate` without JWT → 401 before any business logic
- `POST /api/generate` with text < 200 chars → 400 with exact message "Input too short — paste a full funding announcement or article for best results"
- `POST /api/generate` with `https://127.0.0.1/...` → 400 (SSRF blocked)
- `POST /api/generate` with valid public URL → 200 with `meta.source_type = "url"`
- `POST /api/generate` with raw text → 200 with `meta.source_type = "text"`
- All tests pass: `pytest tests/` exits 0
</success_criteria>

<output>
After completion, create `.planning/phases/01-backend-foundation/01-05-SUMMARY.md`
</output>
